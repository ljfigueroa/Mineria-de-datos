#-------------------------------------------------------------------------------------
# AVISO: este codigo esta adaptado de un paquete mayor.  No es optimo
# y tiene cosas inutiles para nosotros. Es un ejemplo nada mas
#
# general forward greedy selection function
#     x,y inputs and targets
#     method is an external function that estimates classification error
#     with a given model ... parameters for method
# -------------------------------------------------------------------------------------
forward.ranking <- function(x,y,method,verbosity=0,... )
{

	#cantidad de variables
	max.feat<-dim(x)[2]
	num.feat<-1
	#lista con la cantidad de variables
	list.feat<-1:max.feat

	#initial ranking
    x.train<-matrix(0,dim(x)[1],1)
	class.error<-double(max.feat)
	for(i in 1:max.feat){
		# armo un vector con los valores de la variable i
		x.train[,1]<-x[,i]
		# aplico el método a cada variable
		class.error[i] <- do.call(method, c(list(x.train, y), list(...)) )
	}
	#Guardo primera en la lista la variable mínima en error
	list.feat[1]<-which.min(class.error)
	#Guardo en orden creciente las variables que no son la mínima
	keep.feat<-sort(class.error,decreasing=FALSE,index=T)$ix[-1]
	x.prev<-x.train[,1]<-x[,list.feat[1]]

	if(verbosity>1) cat("\nFirst feature: ",list.feat[1],"\n")

	while(num.feat<max.feat){
		class.error<-double(max.feat-num.feat)
		for(i in 1:(max.feat-num.feat)){
			#armo el nuevo conjunto de entrenamiento con la de error minimo mas la variable i
			x.train<-cbind(x.prev,x[,keep.feat[i]])
			class.error[i] <- do.call(method, c(list(x.train, y), list(...)) )
		}
		if(verbosity>2) cat("\nFeatures:\n",keep.feat,"\nErrors:\n",class.error)
		
		# elijo la combinación de menor error
		best.index<-which.min(class.error)
		list.feat[num.feat+1]<-keep.feat[best.index]
		if(verbosity>1) cat("\n---------\nStep ",1+num.feat,"\nFeature ",best.index)

		keep.feat<-keep.feat[-best.index]
		if(verbosity>2) cat("\nNew search list: ",keep.feat)
		num.feat<-num.feat+1
		x.prev<-as.matrix(x[,list.feat[1:num.feat]])
	}


	search.names<-colnames(x)[list.feat]
	imp<-(max.feat:1)/max.feat
	names(imp)<-search.names

	if(verbosity>1){
		cat("\n---------\nFinal ranking ",num.feat," features.")
		cat("\nFeatures: ",search.names,"\n")
	}

 	return( list(ordered.names.list=search.names,ordered.features.list=list.feat,importance=imp) )

}

backward.ranking <- function(x,y,method,... )
{
	numberFeat <- dim(x)[2]
	totalFeat <- 1:numberFeat

	# Características a descartar
	inFeat <- totalFeat
	# Caracteristicas descartadas
	outFeat <- c()

	# Variables a ignorar en cada ciclo del for
	ignoreFeat <- 1
	# Resultado, orden importancia de las variables
	sortFeat <- c()
	while(numberFeat - ignoreFeat > 0){
		#error
		classError <- double(numberFeat - ignoreFeat+1)
		j <- 1
		for(i in inFeat){
			# Genero el cojunto de entrenamiento sin las variables de outFeat e i.
			trainFeat <- totalFeat[-c(outFeat,i)]
			xTrain <- as.matrix(x[trainFeat])
			# Aplico el método
			classError[j] <- do.call(method, c(list(xTrain, y), list(...)) )
			j <- j+1
		}
		# Encuentro la variable que minimizó el error
		worstFeat <- inFeat[which.min(classError)]
		# La descarto y la agrego a la lista de variables descartadas
		outFeat <- c(worstFeat,outFeat)
		sortFeat[numberFeat-ignoreFeat+1] <- worstFeat
		inFeat <- inFeat[-which.min(classError)]
		ignoreFeat <- ignoreFeat+1

	}
	sortFeat[1] <- inFeat[1]
	return (sortFeat)

}

# Kruskal
kruskal.filter <- function(data,class){
	numberFeat <- dim(data)[2]
	classError <- double(numberFeat)

	for (i in 1:numberFeat){
		x <- data[,i]
		classError[i] <- (kruskal.test(x,class)$statistic)
	}

	return (sort(classError,index=T,decreasing=T)$ix)
}

rfe.ranking <- function(x,y,method,... )
{
	numberFeat <- dim(x)[2]
	totalFeat <- 1:numberFeat
	sortFeat <- c()
	train <- x
	inFeat <- totalFeat
	for(i in (totalFeat[-numberFeat])){
		rank.feat <- do.call(method, c(list(train, y), list(...)) )
		worst.feat <- inFeat[rank.feat$feats[1]]
		sortFeat[numberFeat-i+1] <- worst.feat
		inFeat <- inFeat[-rank.feat$feats[1]]
		train <- train[,-rank.feat$feats[1]]
	}
	sortFeat[1] <- inFeat[1]
	return (sortFeat)
}

#---------------------------------------------------------------------------
#random forest error estimation (OOB) for greedy search
#---------------------------------------------------------------------------
rf.est <- function(x.train,y,equalize.classes=TRUE,tot.trees=500,mtry=0)
{
	if(mtry<1) mtry<-floor(sqrt(dim(x.train)[2]))
	prop.samples<-table(y)
	if(equalize.classes) prop.samples<-rep(min(prop.samples),length(prop.samples))
	return( randomForest(x.train,y,mtry=mtry,ntree=tot.trees,sampsize=prop.samples)$err.rate[tot.trees] )
}

#---------------------------------------------------------------------------
#LDA error estimation (LOO) for greedy search
#---------------------------------------------------------------------------
lda.est <- function(x.train,y)
{
	m.lda <- lda(x.train,y,CV=TRUE)
	return(error.rate( y , m.lda$class))
}
error.rate <- function(dataA, dataB) sum( dataA != dataB ) / length(dataB)

#---------------------------------------------------------------------------
#SVM error estimation (internal CV) for greedy search
#---------------------------------------------------------------------------
svm.est <- function(x.train,y,type="C-svc",kernel="vanilladot",C=1,cross = 4)
{
        return ( ksvm(x.train, y, type=type,kernel=kernel,C=C,cross = cross)@cross )
}


#---------------------------------------------------------------------------
#random forest ranking method for rfe.
#---------------------------------------------------------------------------
imp.rf <- function(x.train,y,equalize.classes=TRUE,tot.trees=500,mtry=0)
{
        if(mtry<1) mtry<-floor(sqrt(dim(x.train)[2]))
        prop.samples<-table(y)
        if(equalize.classes) prop.samples<-rep(min(prop.samples),length(prop.samples))

        m.rf<-randomForest(x.train,y,ntree=tot.trees,mtry=mtry,sampsize=prop.samples,importance=TRUE)
        imp.mat<-importance(m.rf)
        imp.col<-dim(imp.mat)[2]-1
        rank.list<-sort(imp.mat[,imp.col],decreasing=FALSE,index=T)
        return(list(feats=rank.list$ix,imp=rank.list$x))
}


#---------------------------------------------------------------------------
#linear svm ranking method for rfe. Using kernlab. Multiclass
#---------------------------------------------------------------------------
imp.linsvm <- function(x.train,y,C=100)
{
	num.feat<-dim(x.train)[2]
	tot.problems<-nlevels(y)*(nlevels(y)-1)/2

	m.svm <- ksvm(as.matrix(x.train), y, type="C-svc",kernel="vanilladot",C=C)

	w<-rep(0.0,num.feat)
	for(i in 1:tot.problems) for(feat in 1:num.feat)
		w[feat]<-w[feat]+abs(m.svm@coef[[i]] %*% m.svm@xmatrix[[i]][,feat])
	rank.list<-sort(w,decreasing=FALSE,index=T)
	return(list(feats=rank.list$ix,imp=rank.list$x))
}

#filter con kruskal esta en las slides


library(randomForest)
library(kernlab)
library(MASS)

#demo: aplicar el wrapper a los datos de iris
data(iris)
FORW.rf <-forward.ranking(iris[,-5],iris[,5],method="rf.est" ,tot.trees=100,equalize.classes=F)
FORW.lda<-forward.ranking(iris[,-5],iris[,5],method="lda.est")


#hacer una funcion que cree datos, 2 clases (-1 y 1,n puntos de cada una), d dimensiones, de ruido uniforme [-1,1], con la clase al azar

crea.ruido.unif<-function(n=100,d=2)
{
        x<-runif(2*n*d,min=-1)	#genero los datos
        dim(x)<-c(2*n,d)
        return(cbind(as.data.frame(x),y=factor(rep(c(-1,1),each=n))))	#le agrego la clase
}

#datosA
d<-10
n<-1000
datos<-crea.ruido.unif(n=n,d=d)

#tomar 50% de los datos al azar, y hacer que la clase sea el signo de la 8 variable
shuffle<-sample(1:dim(datos)[1])
sub<-shuffle[1:dim(datos)[1]*0.5]
datos[sub,d+1]<-sign(datos[sub,8])
#tomar 20% de los datos al azar (fuera de los anteriores), y hacer que la clase sea el signo de la 6 variable
sub<-shuffle[(dim(datos)[1]*0.5):(dim(datos)[1]*0.7)]
datos[sub,d+1]<-sign(datos[sub,6])
#tomar 10% de los datos al azar, y hacer que la clase sea el signo de la 4 variable
sub<-shuffle[(dim(datos)[1]*0.7):(dim(datos)[1]*0.8)]
datos[sub,d+1]<-sign(datos[sub,4])
#tomar 5% de los datos al azar, y hacer que la clase sea el signo de la 2 variable
sub<-shuffle[(dim(datos)[1]*0.8):(dim(datos)[1]*0.85)]
datos[sub,d+1]<-sign(datos[sub,2])
datos[,d+1]<-factor(datos[,d+1])

datosA<-datos

#datosB
#generar n=1000,d=8
d<-8
n<-1000
datos<-crea.ruido.unif(n=n,d=d)
#hacer que la clase sea el xor de las 2 primeras variables (es usando el signo)
datos[,d+1]<-sign(datos[,1]*datos[,2])
#hacer que las variables 3 y 4 tengan un 50% de correlacion con la clase
shuffle<-sample(1:dim(datos)[1])
sub<-shuffle[1:dim(datos)[1]*0.5]
datos[sub,3]<-abs(datos[sub,3])*datos[sub,d+1]
shuffle<-sample(1:dim(datos)[1])
sub<-shuffle[1:dim(datos)[1]*0.5]
datos[sub,4]<-abs(datos[sub,4])*datos[sub,d+1]
datos[,d+1]<-factor(datos[,d+1])

datosB<-datos

